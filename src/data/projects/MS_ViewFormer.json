{
    "id": "jeonhyeonsig2025viewformer",
    "accessed": {
        "date-parts": [
            [
                "2026",
                1,
                5
            ]
        ]
    },
    "author": "전현식, 김유민, 하종은",
    "citation-key": "jeonhyeonsig2025viewformer",
    "container-title": "제어로봇시스템학회 논문지",
    "DOI": "10.5302/J.ICROS.2025.25.0168",
    "ISSN": "1976-5622",
    "issue": "10",
    "issued": {
        "date-parts": [
            [
                "2025",
                10
            ]
        ]
    },
    "page": "1160–1168",
    "source": "www.dbpia.co.kr",
    "title": "Object Mask Module for Enhancing Multi-view 3D Occupancy Perception Performance Based on ViewFormer",
    "type": "article-journal",
    "URL": "https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE12406310",
    "volume": "31",
    "category": "domestic-journal",
    "year": 2025,
    "venue": "제어로봇시스템학회 논문지",
    "language": "Ko",
    "organizations": [
        {
            "name": "ICROS",
            "url": "https://icros.org/eng/"
        }
    ],
    "doi": "10.5302/J.ICROS.2025.25.0168",
    "abstract": "• **Problem**: ViewFormer effectively captures spatiotemporal information but **underperforms on small objects** such as pedestrians and bicycles.\n• **Solution**: Designed a **SegFormer-based object masking module** that estimates object probabilities from BEV features and concatenates them as an additional feature channel.\n• **Result**: Experimental evaluations on the nuScenes dataset revealed an **unexpected performance decline** in overall metrics, and subsequent analysis indicated **weak mask activation and instability** during initial training, highlighting the need for **structural adjustments and improved training strategies** in future work.",
    "media": [
        {
            "type": "image",
            "url": "/assets/project/Viewformer_Fig_1.webp",
            "caption": "Overall architecture of ViewFormer with the proposed Object Mask module."
        }
    ],
    "tables": [
        {
            "caption": "Comparison of model performance.",
            "columns": [
                "Method",
                "Training GPU",
                "Test GPU",
                "Training Time",
                "Memory(G)",
                "FPS",
                "FLOPs",
                "Params",
                "IoUgeo",
                "mIoU"
            ],
            "rows": [
                [
                    "ViewFormer",
                    "4090*2",
                    "4090*2",
                    "5D 22h",
                    "13.7",
                    "12.2",
                    "214.74",
                    "99.19 M",
                    "71.03",
                    "41.37"
                ],
                [
                    "Try 1 (126⊙126) CNN",
                    "4090*2",
                    "4090*2",
                    "7D 7h",
                    "14.1",
                    "6.2",
                    "242.14",
                    "99.28 M",
                    "62.48",
                    "25.45"
                ],
                [
                    "Try 2 (126⊕1) CNN",
                    "4090*2",
                    "4090*2",
                    "6D 23h",
                    "13.7",
                    "12.1",
                    "242.14",
                    "99.28 M",
                    "62.76",
                    "25.73"
                ],
                [
                    "Ours (126⊕1) Seg",
                    "4090*2",
                    "4090*2",
                    "9D 5h",
                    "16.2",
                    "10.7",
                    "249.30",
                    "181.21 M",
                    "64.89",
                    "28.76"
                ]
            ],
            "highlightRowIndex": 3
        },
        {
            "caption": "Early performance comparison when training the Seg model on a single GPU.",
            "columns": [
                "Method",
                "Training GPU",
                "Test GPU",
                "Training Time",
                "Memory(G)",
                "FPS",
                "FLOPs",
                "Params",
                "IoUgeo",
                "mIoU"
            ],
            "rows": [
                [
                    "ViewFormer",
                    "3090*1",
                    "1/10",
                    "22D",
                    "14.6",
                    "-",
                    "-",
                    "99.19 M",
                    "62.88",
                    "27.36"
                ],
                [
                    "Ours - single (126⊕1) Seg",
                    "3090*1",
                    "1/10",
                    "32D",
                    "14.9",
                    "-",
                    "-",
                    "181.21 M",
                    "62.53",
                    "28.28"
                ]
            ],
            "highlightRowIndex": 1
        }
    ],
    "resultImages": [
        {
            "url": "/assets/project/Viewformer_Fig_2.webp",
            "caption": "Ground truth mask for object mask learning."
        },
        {
            "url": "/assets/project/Viewformer_Fig_3.webp",
            "caption": "Visualization of BEV feature changes caused by the application of object masks across different stages of training."
        }
    ]
}